# Sistema Recomendador de Moda Multimodal

Este proyecto implementa un sistema recomendador de moda hÃ­brido que combina elementos visuales y textuales usando Vision Transformer, BERT y mecanismos de atenciÃ³n cross-modal.

## ğŸ—ï¸ Arquitectura del Modelo

### Componentes Principales

1. **Vision Transformer (ViT)**: Procesa las imÃ¡genes de los artÃ­culos de moda
2. **BERT**: Procesa las descripciones textuales de los productos
3. **AtenciÃ³n Cross-Modal**: Fusiona informaciÃ³n visual y textual
4. **Aprendizaje Contrastivo**: Optimiza las representaciones para recomendaciÃ³n

### Flujo del Modelo

```
Imagen â†’ ViT â†’ Embeddings Visuales
                                    â†˜
                                      Cross-Modal Attention â†’ FusiÃ³n â†’ Embedding Final
                                    â†—
Texto â†’ BERT â†’ Embeddings Textuales
```

## ğŸ“Š Dataset: H&M Personalized Fashion Recommendations

### Archivos de Datos
- `transactions_clean.csv`: Historial de compras de clientes
- `articles_clean.csv`: Metadatos detallados de artÃ­culos
- `customers_clean.csv`: InformaciÃ³n de clientes
- `normalized_images/`: ImÃ¡genes de productos organizadas por carpetas

### CaracterÃ­sticas del Dataset
- **Modalidad Visual**: ImÃ¡genes de productos de moda
- **Modalidad Textual**: Descripciones, categorÃ­as, colores, etc.
- **Datos Temporales**: Transacciones con timestamps
- **Escala**: Miles de productos y millones de transacciones

## ğŸš€ ConfiguraciÃ³n para Google Colab

### Paso 1: ConfiguraciÃ³n Inicial

```python
# Ejecutar en la primera celda
!git clone <repository-url>
%cd /content/model/training
!python colab_setup.py
```

### Paso 2: Subir Datos

1. Subir los archivos de datos a `/content/cleaned-data/`
2. Asegurarse de que la estructura de carpetas sea correcta:
   ```
   /content/cleaned-data/
   â”œâ”€â”€ transactions_clean.csv
   â”œâ”€â”€ articles_clean.csv  
   â”œâ”€â”€ customers_clean.csv
   â””â”€â”€ normalized_images/
       â”œâ”€â”€ 010/
       â”œâ”€â”€ 011/
       â””â”€â”€ ...
   ```

### Paso 3: Entrenamiento

```python
# Entrenamiento bÃ¡sico
!python main.py

# Entrenamiento con configuraciÃ³n personalizada
!python main.py --batch_size 16 --max_epochs 3 --learning_rate 3e-5

# Entrenamiento sin Wandb
!python main.py --no_wandb
```

## âš™ï¸ ConfiguraciÃ³n del Modelo

### ParÃ¡metros Principales

```python
# ConfiguraciÃ³n del modelo
model_config = {
    "vit_model_name": "google/vit-base-patch16-224",
    "bert_model_name": "bert-base-uncased", 
    "cross_modal_num_layers": 4,
    "cross_modal_num_heads": 12,
    "temperature": 0.07
}

# ConfiguraciÃ³n de datos
data_config = {
    "batch_size": 32,
    "streaming_buffer_size": 1000,
    "num_negative_samples": 5,
    "image_size": 224,
    "max_text_length": 128
}

# ConfiguraciÃ³n de entrenamiento
training_config = {
    "learning_rate": 5e-5,
    "max_epochs": 5,
    "patience": 3,
    "gradient_accumulation_steps": 4
}
```

### Optimizaciones para Colab

- **Carga en Streaming**: Los datos se cargan en chunks para evitar OOM
- **Batch Size Adaptativo**: Se ajusta automÃ¡ticamente segÃºn la GPU disponible
- **Gradient Accumulation**: Para simular batch sizes mÃ¡s grandes
- **Mixed Precision**: Reduce uso de memoria y acelera entrenamiento
- **Checkpointing**: Guarda progreso regularmente

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

### MÃ©tricas Implementadas

1. **Precision@K**: PrecisiÃ³n en las top-K recomendaciones
2. **Recall@K**: Recall en las top-K recomendaciones  
3. **NDCG@K**: Normalized Discounted Cumulative Gain
4. **Hit Rate@K**: Porcentaje de usuarios con al menos un hit
5. **MRR**: Mean Reciprocal Rank
6. **MAP**: Mean Average Precision
7. **Coverage**: Cobertura del catÃ¡logo
8. **Diversity**: Diversidad intra-lista

### Valores K Evaluados
- K = [5, 10, 20, 50]

## ğŸ”§ Uso del Sistema

### Entrenamiento Completo

```python
from config import Config
from data_loader import create_data_loaders
from trainer import FashionRecommenderTrainer

# ConfiguraciÃ³n
config = Config()

# Crear data loaders
train_loader, test_loader = create_data_loaders(config)

# Entrenar modelo
trainer = FashionRecommenderTrainer(config, train_loader, test_loader)
trainer.train()
```

### Inferencia

```python
# Cargar modelo entrenado
model = MultiModalFashionRecommender(config)
checkpoint = torch.load('checkpoints/best_model.pt')
model.load_state_dict(checkpoint['model_state_dict'])

# Obtener embeddings de artÃ­culos
embeddings = model(images, input_ids, attention_mask)

# Calcular similitudes para recomendaciÃ³n
similarities = torch.mm(user_embedding, item_embeddings.t())
recommendations = torch.argsort(similarities, descending=True)
```

## ğŸ“ Estructura del Proyecto

```
training/
â”œâ”€â”€ __init__.py              # InicializaciÃ³n del paquete
â”œâ”€â”€ config.py               # Configuraciones del sistema
â”œâ”€â”€ model.py                # Arquitectura del modelo multimodal
â”œâ”€â”€ data_loader.py          # Carga de datos en streaming
â”œâ”€â”€ trainer.py              # Loop de entrenamiento
â”œâ”€â”€ metrics.py              # MÃ©tricas de evaluaciÃ³n
â”œâ”€â”€ main.py                 # Script principal de entrenamiento
â”œâ”€â”€ colab_setup.py          # ConfiguraciÃ³n para Google Colab
â”œâ”€â”€ requirements.txt        # Dependencias
â””â”€â”€ README.md              # DocumentaciÃ³n
```

## ğŸ¯ CaracterÃ­sticas Clave

### Streaming de Datos
- Carga datos en chunks para manejar datasets grandes
- Buffer configurable para balance memoria/velocidad
- Compatible con limitaciones de memoria de Colab

### AtenciÃ³n Cross-Modal
- FusiÃ³n bidireccional entre modalidades visual y textual
- MÃºltiples capas de atenciÃ³n para capturar interacciones complejas
- NormalizaciÃ³n por capas y conexiones residuales

### Aprendizaje Contrastivo
- Muestreo negativo inteligente
- Temperatura ajustable para control de la distribuciÃ³n
- OptimizaciÃ³n para ranking de recomendaciones

### Optimizaciones para ProducciÃ³n
- Mixed precision training
- Gradient accumulation
- Checkpointing automÃ¡tico
- Early stopping
- Logging con Wandb

## ğŸ” Monitoreo del Entrenamiento

### Wandb Dashboard
- PÃ©rdida de entrenamiento en tiempo real
- MÃ©tricas de evaluaciÃ³n
- Uso de memoria y GPU
- HiperparÃ¡metros

### Logs Locales
- Archivo `training.log` con informaciÃ³n detallada
- MÃ©tricas por Ã©poca y paso
- InformaciÃ³n de checkpoints

## âš¡ Consejos de OptimizaciÃ³n

### Para T4 GPU (< 12GB)
```python
config.data.batch_size = 16
config.training.gradient_accumulation_steps = 8
config.data.streaming_buffer_size = 500
```

### Para P100/V100 (12-16GB)
```python
config.data.batch_size = 24
config.training.gradient_accumulation_steps = 6
config.data.streaming_buffer_size = 750
```

### Para A100 (> 16GB)
```python
config.data.batch_size = 32
config.training.gradient_accumulation_steps = 4
config.data.streaming_buffer_size = 1000
```

## ğŸ› SoluciÃ³n de Problemas

### Out of Memory (OOM)
1. Reducir `batch_size`
2. Aumentar `gradient_accumulation_steps`
3. Reducir `streaming_buffer_size`
4. Activar `mixed_precision`

### Entrenamiento Lento
1. Aumentar `batch_size` si hay memoria disponible
2. Usar `num_workers > 0` si no estÃ¡ en Colab
3. Verificar que se estÃ¡ usando GPU

### Datos No Encontrados
1. Verificar rutas en `config.data.data_dir`
2. Asegurar estructura correcta de carpetas
3. Comprobar permisos de archivos

## ğŸ“š Referencias

- Vision Transformer: "An Image is Worth 16x16 Words"
- BERT: "Bidirectional Encoder Representations from Transformers"  
- Cross-Modal Attention: "Attention is All You Need"
- Contrastive Learning: "A Simple Framework for Contrastive Learning"

## ğŸ¤ ContribuciÃ³n

Para contribuir al proyecto:
1. Fork el repositorio
2. Crear una branch para tu feature
3. Hacer commit de los cambios
4. Push a la branch
5. Crear un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver `LICENSE` para mÃ¡s detalles.
